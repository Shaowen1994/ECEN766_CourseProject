{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_dict = {'A':0,'R':1,'N':2,'D':3,'C':4,'Q':5,'E':6,'G':7,'H':8,'I':9,'L':10,\n",
    "           'K':11,'M':12,'F':13,'P':14,'S':15,'T':16,'W':17,'Y':18,'V':19,'!':20}\n",
    "SS_dict = {'H':0,'E':1,'C':2}\n",
    "\n",
    "def one_hot_encoding(seq,ref_dict,width=None):\n",
    "    if width == None:\n",
    "        width = len(ref_dict.keys())\n",
    "    L = len(seq)\n",
    "    result = np.zeros([L,width])\n",
    "    for i in range(L):\n",
    "        result[i][ref_dict[seq[i]]] = 1\n",
    "    return result.reshape(-1)\n",
    "\n",
    "def load_segments(seg_file):\n",
    "    with open(seg_file,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    seg_len = len(lines[0].split('\\t')[0])\n",
    "    data_size = len(lines)\n",
    "    X = []\n",
    "    Y = []\n",
    "    for line in lines:\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        X.append(one_hot_encoding(line[0],AA_dict))\n",
    "        Y.append(SS_dict[line[1]])\n",
    "    return np.array(X),np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_path = '../Data/Datasets/For_Seq_SS/'\n",
    "\n",
    "X_train_3, Y_train_3 = load_segments(Data_path + 'Segments_train_3')\n",
    "X_train_5, Y_train_5 = load_segments(Data_path + 'Segments_train_5')\n",
    "X_train_7, Y_train_7 = load_segments(Data_path + 'Segments_train_7')\n",
    "\n",
    "X_vali_3, Y_vali_3 = load_segments(Data_path + 'Segments_vali_3')\n",
    "X_vali_5, Y_vali_5 = load_segments(Data_path + 'Segments_vali_5')\n",
    "X_vali_7, Y_vali_7 = load_segments(Data_path + 'Segments_vali_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model,X_vali,Y_vali):\n",
    "    pred = model.predict(X_vali)\n",
    "    return list(pred == Y_vali).count(True)/X_vali.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuraccy: 0.553\n",
      "Training Time: 221.544 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf_3 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(100, 100, 100), random_state=1)\n",
    "clf_3.fit(X_train_3,Y_train_3)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "vali_3 = validation(clf_3,X_vali_3,Y_vali_3)\n",
    "\n",
    "print('Validation Accuraccy: %.3f'%vali_3)\n",
    "print('Training Time: %.3f s'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuraccy: 0.591\n",
      "Training Time: 226.025 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf_5 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(100, 100, 100), random_state=1)\n",
    "clf_5.fit(X_train_5,Y_train_5)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "vali_5 = validation(clf_5,X_vali_5,Y_vali_5)\n",
    "\n",
    "print('Validation Accuraccy: %.3f'%vali_5)\n",
    "print('Training Time: %.3f s'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuraccy: 0.611\n",
      "Training Time: 230.125 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf_7 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(100, 100, 100), random_state=1)\n",
    "clf_7.fit(X_train_7,Y_train_7)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "vali_7 = validation(clf_7,X_vali_7,Y_vali_7)\n",
    "\n",
    "print('Validation Accuraccy: %.3f'%vali_7)\n",
    "print('Training Time: %.3f s'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Model/FCNN/FCNN_7.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Path = '../Model/FCNN/'\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "dump(clf_3,Model_Path + 'FCNN_3.joblib')\n",
    "dump(clf_5,Model_Path + 'FCNN_5.joblib')\n",
    "dump(clf_7,Model_Path + 'FCNN_7.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_dict_reverse = {0:'H',1:'E',2:'C'}\n",
    "\n",
    "def ss_predict(model,seq,padding_num,AA_dict,SS_dict_reverse):\n",
    "    seq_pad = '!'*padding_num + seq + '!'*padding_num\n",
    "    ss = ''\n",
    "    for i in range(len(seq)):\n",
    "        seg = seq_pad[i:padding_num*2+i+1]\n",
    "        s_vec = one_hot_encoding(seg,AA_dict)\n",
    "        ss += SS_dict_reverse[model.predict([s_vec])[0]]\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(model,seq_list,ss_list,padding_num,AA_dict,SS_dict_reverse):\n",
    "    l = len(seq_list)\n",
    "    if l != len(ss_list):\n",
    "        print('Error!')\n",
    "        return None\n",
    "    else:\n",
    "        resi_num = 0\n",
    "        corr_num = 0\n",
    "        for i in range(l):\n",
    "            seq = seq_list[i]\n",
    "            ss = ss_list[i]\n",
    "            resi_num += len(seq)\n",
    "            ss_pre = ss_predict(model,seq,padding_num,AA_dict,SS_dict_reverse)\n",
    "            corr_num += list(np.array(list(ss_pre)) == np.array(list(ss))).count(True)\n",
    "            return corr_num / resi_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.833\n"
     ]
    }
   ],
   "source": [
    "with open(Data_path + 'SeqSS_seq_test','r') as seq_f, open(Data_path + 'SeqSS_ss_test','r') as ss_f:\n",
    "    seq_list = [s.strip('\\n') for s in seq_f.readlines()]\n",
    "    ss_list = [s.strip('\\n') for s in ss_f.readlines()]\n",
    "    Test_Accu = Evaluate(clf_7,seq_list,ss_list,3,AA_dict,SS_dict_reverse)\n",
    "    \n",
    "print('Test Accuracy: %.3f'% Test_Accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Amount: 1769\n",
      "\n",
      "\tTest Accuracy (seglength = 3): 0.706\n",
      "Inference Time: 0.045 s\n",
      "\n",
      "\tTest Accuracy (seglength = 5): 0.738\n",
      "Inference Time: 0.032 s\n",
      "\n",
      "\tTest Accuracy (seglength = 7): 0.833\n",
      "Inference Time: 0.057 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Sequence Amount: %d'%len(seq_list))\n",
    "print()\n",
    "\n",
    "model_dict = {3:clf_3,5:clf_5,7:clf_7}\n",
    "    \n",
    "\n",
    "for sl in model_dict.keys():\n",
    "    start = time.time()\n",
    "    accu = Evaluate(model_dict[sl],seq_list,ss_list,int((sl - 1)/2),AA_dict,SS_dict_reverse)\n",
    "    end = time.time()\n",
    "    print(\"\\tTest Accuracy (seglength = %d): %.3f\"%(sl,accu))\n",
    "    print(\"Inference Time: %.3f s\"%(end - start))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
